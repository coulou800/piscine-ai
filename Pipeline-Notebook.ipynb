{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Imputer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [[7, 6, 5],\n",
    "              [4, np.nan, 5],\n",
    "              [1, 20, 8]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Fit the SimpleImputer on the data. Print the statistics_. Check that the statistics match np.nanmean(train_data, axis=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic: [ 4. 13.  6.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[7, 6, 5], [4, nan, 5], [1, 20, 8]]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "simp = SimpleImputer()\n",
    "\n",
    "simp.fit(train_data)\n",
    "\n",
    "print(f\"statistic: {simp.statistics_}\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Fill the missing values in train_data using the fitted imputer and transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  6.,  5.],\n",
       "       [ 4., 13.,  5.],\n",
       "       [ 1., 20.,  8.]])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simp.transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Fill the missing values in test_data using the fitted imputer and transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  1.,  2.],\n",
       "       [ 7., 13.,  9.],\n",
       "       [ 4.,  2.,  4.]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = [[np.nan, 1, 2],\n",
    "             [7, np.nan, 9],\n",
    "             [np.nan, 2, 4]]\n",
    "\n",
    "simp.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                     [ 2.,  0.,  0.],\n",
    "                     [ 0.,  1., -1.]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Fit the StandardScaler on the data and scale X_train using fit_transform. Compute the mean and std on axis 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Scale the test set using the StandardScaler fitted on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22474487, -1.22474487,  0.53452248],\n",
       "       [ 2.44948974,  3.67423461, -1.06904497],\n",
       "       [ 0.        ,  1.22474487,  0.53452248]])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[ 2., -1.,  1.],\n",
    "                     [ 3.,  3.,  -1.],\n",
    "                     [ 1.,  1., 1.]])\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: One hot Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Using OneHotEncoder with handle_unknown='ignore', fit the One Hot Encoder and transform X_train. The expected output is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C++</th>\n",
       "      <th>Java</th>\n",
       "      <th>Python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C++  Java  Python\n",
       "0    0     0       1\n",
       "1    0     1       0\n",
       "2    0     1       0\n",
       "3    1     0       0"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train = [['Python'], ['Java'], ['Java'], ['C++']]\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoded = encoder.fit_transform(X_train)\n",
    "\n",
    "pd.DataFrame(encoded.toarray(), columns=encoder.categories_[0],dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Transform X_test using the fitted One Hot Encoder on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C++</th>\n",
       "      <th>Java</th>\n",
       "      <th>Python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C++  Java  Python\n",
       "0    0     0       1\n",
       "1    0     1       0\n",
       "2    0     0       0\n",
       "3    1     0       0"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [['Python'], ['Java'], ['C'], ['C++']]\n",
    "\n",
    "encoded_test = encoder.transform(X_test)\n",
    "pd.DataFrame(encoded_test.toarray(), columns=encoder.categories_[0],dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Ordinal Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Fit the OrdinalEncoder by specifying the categories in the following order: categories=[['bad', 'neutral', 'good']]. Transform the train set. Print the categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array(['bad', 'neutral', 'good'], dtype=object)]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "X_train = [['good'], ['bad'], ['neutral']]\n",
    "\n",
    "oencd = OrdinalEncoder(categories=[['bad', 'neutral', 'good']])\n",
    "transformed =  oencd.fit_transform(X_train)\n",
    "\n",
    "print(transformed)\n",
    "oencd.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Transform the X_test using the fitted Ordinal Encoder on train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [2.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [['good'], ['good'], ['bad']]\n",
    "\n",
    "transformed = oencd.transform(X_test)\n",
    "transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing value: 9\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "cols = [\n",
    "\"age\"\n",
    ",\"menopause\"\n",
    ",\"tumor-size\"\n",
    ",\"inv-nodes\"\n",
    ",\"node-caps\"\n",
    ",\"deg-malig\"\n",
    ",\"breast\"\n",
    ",\"breast-quad\"\n",
    ",\"irradiat\",\n",
    "\"Class\"]\n",
    "data = pd.read_csv(\"data/breast-cancer.csv\",names=cols)\n",
    "\n",
    "#check num of missing value\n",
    "print(f\"number of missing value: {data.isnull().sum().sum()}\")\n",
    "# drop row (axix=0) containing missing value\n",
    "data.dropna(axis=0,inplace=True)\n",
    "\n",
    "# split train,test dataset\n",
    "# y = data[\"Class\"] #target\n",
    "# X = data.drop(\"Class\",axis=1) # features\n",
    "X_train,X_test = train_test_split(data,test_size=0.2, random_state=43)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Count the number of unique values per feature in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age             6\n",
       "menopause       3\n",
       "tumor-size     11\n",
       "inv-nodes       6\n",
       "node-caps       2\n",
       "deg-malig       3\n",
       "breast          2\n",
       "breast-quad     5\n",
       "irradiat        2\n",
       "Class           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Data transformation- OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "       [1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.],\n",
       "       [1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "       [1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonordcols =['node-caps' , 'breast', 'breast-quad', 'irradiat']\n",
    "oneHotEnc = OneHotEncoder(handle_unknown='ignore')\n",
    "oneHotEnc.fit(X_train[nonordcols])\n",
    "\n",
    "nonord = X_test[nonordcols]\n",
    "\n",
    "nord_t = oneHotEnc.transform(nonord)\n",
    "\n",
    "nord_t.toarray()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Data transformation- OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 5., 2., 0., 1.],\n",
       "       [2., 5., 2., 0., 0.],\n",
       "       [2., 5., 4., 5., 2.],\n",
       "       [1., 4., 5., 1., 1.],\n",
       "       [2., 5., 5., 0., 2.],\n",
       "       [1., 2., 1., 0., 1.],\n",
       "       [1., 2., 8., 0., 1.],\n",
       "       [2., 5., 2., 0., 0.],\n",
       "       [2., 5., 5., 0., 2.],\n",
       "       [1., 2., 3., 0., 0.]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordenc = OrdinalEncoder(\n",
    "    categories=[\n",
    "        ['lt40','premeno','ge40'],\n",
    "        [ '10-19','20-29','30-39','40-49','50-59', '60-69','70-79','80-89','90-99' ],\n",
    "        ['0-4', '5-9', '10-14', '15-19', '20-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59'],\n",
    "        ['0-2', '3-5', '6-8', '9-11', '12-14', '15-17', '18-20', '21-23', '24-26', '27-29', '30-32', '33-35', '36-39'],\n",
    "        ['1', '2', '3']\n",
    "    ],\n",
    ")\n",
    "ordcols = [\"menopause\", \"age\", \"tumor-size\",\"inv-nodes\", \"deg-malig\"]\n",
    "\n",
    "ordinal =X_train[ordcols]\n",
    "ordenc.fit(ordinal)\n",
    "ord_t = ordenc.transform(X_test[ordcols])\n",
    "ord_t[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Use a make_column_transformer to combine the two Encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 2., 5., 2., 0., 1.],\n",
       "       [1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 2., 5., 2., 0., 0.]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "columnTransformer = make_column_transformer((oneHotEnc,nonordcols),(ordenc,ordcols))\n",
    "\n",
    "columnTransformer.fit(X_train)\n",
    "\n",
    "combined = columnTransformer.transform(X_test)\n",
    "\n",
    "combined[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this exercise is to learn to use the Scikit-learn object: Pipeline. The data set: used for this exercise is the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris['data'], iris['target']\n",
    "\n",
    "#add missing values\n",
    "X[[1,20,50,100,135], 0] = np.nan\n",
    "X[[2,5,88,135], 1] = np.nan\n",
    "X[[4,15], 2] = np.nan\n",
    "X[[40,135], 3] = np.nan\n",
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.33, random_state=43)\n",
    " \n",
    "#implement imputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train_imp = imputer.fit_transform(X_train,y_train)\n",
    "\n",
    "X_test_imp = imputer.transform(X_test)\n",
    "\n",
    "#implement scaler\n",
    "stdScaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = stdScaler.fit_transform(X_train_imp)\n",
    "X_test_scaled = stdScaler.transform(X_test_imp)\n",
    "\n",
    "#training the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train_scaled,y_train)\n",
    "\n",
    "#check the accuracy of the model\n",
    "score = model.score(X_test_scaled,y_test)\n",
    "\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex00",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
