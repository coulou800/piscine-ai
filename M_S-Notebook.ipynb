{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[2 3 4 5 6 7 8 9]\n",
      "  Test:  index=[0 1]\n",
      "Fold 1:\n",
      "  Train: index=[0 1 4 5 6 7 8 9]\n",
      "  Test:  index=[2 3]\n",
      "Fold 2:\n",
      "  Train: index=[0 1 2 3 6 7 8 9]\n",
      "  Test:  index=[4 5]\n",
      "Fold 3:\n",
      "  Train: index=[0 1 2 3 4 5 8 9]\n",
      "  Test:  index=[6 7]\n",
      "Fold 4:\n",
      "  Train: index=[0 1 2 3 4 5 6 7]\n",
      "  Test:  index=[8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "X = np.array(np.arange(1,21).reshape(10,-1))\n",
    "y = np.array(np.arange(1,11))\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "    print(f\"Fold {i}:\")\n",
    "\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Cross validation (k-fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import California Housing data set and split it in a train set and a test set (10%). Fit a linear regression on the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# data\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "# split data train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=43)\n",
    "# pipeline\n",
    "pipeline = [('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('lr', LinearRegression())]\n",
    "pipe = Pipeline(pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Cross validate the Pipeline using cross_validate with 10 folds. Print the scores on each validation sets, the mean score on the validation sets and the standard deviation on the validation sets. The expected output is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      scores:\n",
      "      [0.62433594 0.61648956 0.62486602 0.59891024 0.59284295 0.61307055\n",
      " 0.54630341 0.60742976 0.60014575 0.59574508]\n",
      "      \n",
      "      mean score:\n",
      "      0.60201392526743\n",
      "      \n",
      "      score std:\n",
      "      0.021498382277346514\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(pipe,cv=10,X=X_train,y=y_train)\n",
    "\n",
    "print(f\"\"\"\n",
    "      scores:\n",
    "      {scores[\"test_score\"]}\n",
    "      \n",
    "      mean score:\n",
    "      {scores[\"test_score\"].mean()}\n",
    "      \n",
    "      score std:\n",
    "      {scores[\"test_score\"].std()}\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: GridsearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import California Housing dataset, split it into a train and a test set (10%), and fit a linear regression on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "# split data train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=43)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 10, 17], &#x27;n_estimators&#x27;: [5, 25, 75]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 10, 17], &#x27;n_estimators&#x27;: [5, 25, 75]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [3, 10, 17], 'n_estimators': [5, 25, 75]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": [3,10,17],\n",
    "    \"n_estimators\": [5,25,75]\n",
    "}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(RandomForestRegressor(),params,n_jobs=-1,scoring=\"neg_mean_squared_error\",cv=5)\n",
    "\n",
    "gs.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.25651419170139184\n",
      "{'max_depth': 17, 'n_estimators': 75}\n",
      "{'mean_fit_time': array([ 0.71401229,  5.15041833, 19.70704246,  3.71968117, 16.94802709,\n",
      "       54.50932012,  5.8641705 , 25.73737807, 71.52938385]), 'std_fit_time': array([0.05809767, 2.48340725, 2.46942152, 0.44960276, 0.93439149,\n",
      "       1.89342675, 0.38975466, 1.12371502, 8.31944346]), 'mean_score_time': array([0.00644708, 0.07303758, 0.15892658, 0.0262517 , 0.07668123,\n",
      "       0.24366021, 0.02862353, 0.12535911, 0.39007583]), 'std_score_time': array([0.0028581 , 0.0578816 , 0.07604941, 0.01163342, 0.01754787,\n",
      "       0.02667528, 0.00568905, 0.0134795 , 0.11039135]), 'param_max_depth': masked_array(data=[3, 3, 3, 10, 10, 10, 17, 17, 17],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[5, 25, 75, 5, 25, 75, 5, 25, 75],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 3, 'n_estimators': 5}, {'max_depth': 3, 'n_estimators': 25}, {'max_depth': 3, 'n_estimators': 75}, {'max_depth': 10, 'n_estimators': 5}, {'max_depth': 10, 'n_estimators': 25}, {'max_depth': 10, 'n_estimators': 75}, {'max_depth': 17, 'n_estimators': 5}, {'max_depth': 17, 'n_estimators': 25}, {'max_depth': 17, 'n_estimators': 75}], 'split0_test_score': array([-0.55202732, -0.55030701, -0.55141009, -0.29594204, -0.26360292,\n",
      "       -0.26045839, -0.27567213, -0.23688218, -0.2284503 ]), 'split1_test_score': array([-0.61025257, -0.60878172, -0.60204782, -0.31349364, -0.29587898,\n",
      "       -0.28771115, -0.32834102, -0.25933066, -0.25638283]), 'split2_test_score': array([-0.60026913, -0.60302392, -0.60420828, -0.33978211, -0.30861151,\n",
      "       -0.29805675, -0.32733907, -0.27254117, -0.25866314]), 'split3_test_score': array([-0.5962853 , -0.58841368, -0.59344273, -0.33325705, -0.30539774,\n",
      "       -0.30277905, -0.32402996, -0.28308703, -0.26858472]), 'split4_test_score': array([-0.62420969, -0.61711182, -0.60718576, -0.33138073, -0.30809731,\n",
      "       -0.29935059, -0.31878346, -0.27671254, -0.27048997]), 'mean_test_score': array([-0.5966088 , -0.59352763, -0.59165894, -0.32277111, -0.29631769,\n",
      "       -0.28967119, -0.31483313, -0.26571072, -0.25651419]), 'std_test_score': array([0.02428569, 0.02355103, 0.02063806, 0.01599578, 0.01698701,\n",
      "       0.01544703, 0.01986269, 0.01637938, 0.01505482]), 'rank_test_score': array([9, 8, 7, 6, 4, 3, 5, 2, 1], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Validation curve and Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "max_depth_range = np.arange(1,21)\n",
    "\n",
    "X, y = make_classification(n_samples=100000,\n",
    "                        n_features= 30,\n",
    "                        n_informative=10,\n",
    "                        flip_y=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "(train_score, test_score) = validation_curve(\n",
    "    RandomForestClassifier(),\n",
    "    X,y,    param_name=\"max_depth\",\n",
    "    param_range=max_depth_range,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "plt.plot(max_depth_range,train_score.mean(axis=1),label=\"Training Score\")\n",
    "plt.plot(max_depth_range,test_score.mean(axis=1),label=\"Testing Score\")\n",
    "\n",
    "plt.set_title(\"Validation Curve: max_depth\")\n",
    "plt.set_xlabel(\"max_depth\")\n",
    "plt.set_ylabel(\"Score: ROC AUC\")\n",
    "plt.set_ylim(0.0, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=12)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    clf, X, y, cv=5, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid()\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex00",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
