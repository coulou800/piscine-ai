{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Logistic regression in Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0],[0.1],[0.2], [1],[1.1],[1.2], [1.3]]) \n",
    "y = np.array([0,0,0,1,1,1,0]) \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "cls = KNeighborsClassifier()\n",
    "cls.fit(X,y)\n",
    "\n",
    "x_pred =cls.predict([[0.5]])\n",
    "x_prob = cls.predict_proba([[0.5]])\n",
    "\n",
    "reg = LogisticRegression()\n",
    "\n",
    "reg.fit(X,y)\n",
    "\n",
    "print(f\"\"\"\n",
    "1. xpred = {x_pred}\n",
    "2. xpred probabilities = {x_prob}\n",
    "3. coef = {reg.coef_}; intercept = {reg.intercept_}; score = {reg.score(X,y)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-20, 15, 300)\n",
    "\n",
    "sigmoid1  = 1/(1+ np.exp(-(0.5*x + 3)))\n",
    "sigmoid2 = 1/(1+ np.exp(-(5*x + 11)))\n",
    "sigmoid = 1/(1+ np.exp(-x))\n",
    "\n",
    "plt.plot(x,sigmoid)\n",
    "plt.plot(x,sigmoid1)\n",
    "plt.plot(x,sigmoid2)\n",
    "plt.axhline(y=0.5,color='red')\n",
    "\n",
    "plt.title(\"Sigmoids\")\n",
    "plt.xlabel(\"X\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "X,y = make_classification(\n",
    "    n_samples=100,\n",
    "    n_features=1,\n",
    "    n_informative=1,\n",
    "    n_redundant=0,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.5,0.5],\n",
    "    flip_y=0.15,\n",
    "    class_sep=2.0,\n",
    "    hypercube=True,\n",
    "    shift=1.0,\n",
    "    scale=1.0,\n",
    "    shuffle=True,\n",
    "    random_state=88\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Plot the data using a scatter plot. The x-axis contains the feature and y-axis contains the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"X (1 dimension) and y\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Fit a Logistic Regression on the generated data using scikit learn. Print the coefficients and the interception of the Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression()\n",
    "\n",
    "lreg.fit(X,y)\n",
    "\n",
    "print(f\"\"\"\n",
    "coef = {lreg.coef_}\n",
    "intercept = {reg.intercept_}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Add to the previous plot the fitted sigmoid and the 0.5 probability line. The plot should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3,4)\n",
    "sigmoid =lambda x: 1/(1+np.exp(-x))\n",
    "y_prob = sigmoid(x*lreg.coef_[0][0]+lreg.intercept_[0])\n",
    "plt.title(\"X (1 dimension) and y\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "\n",
    "plt.scatter(X,y)\n",
    "plt.plot(x,y_prob,color=\"orange\")\n",
    "plt.plot([-3,4],[0.5,0.5],color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Create a function predict_probability that takes as input the data point and the coefficients and that returns the predicted probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probability(coefs, X):\n",
    "    '''\n",
    "    coefs is a list that contains a and b: [coef, intercept]\n",
    "    X is the features set\n",
    "\n",
    "    Returns probability of X\n",
    "    '''\n",
    "    probabilities = sigmoid(coefs[0]*X + coefs[1])\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "lreg.fit(X,y)\n",
    "x_prob = lreg.predict_proba(X)\n",
    "coefs = [lreg.coef_[0][0],lreg.intercept_[0]]\n",
    "x_prob1 = predict_probability(coefs,X)\n",
    "\n",
    "x_prob[:3],x_prob1[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Create a function predict_class that takes as input the data point and the coefficients and that returns the predicted class. Check you have the same results as the class method predict output on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(coefs, X: np.ndarray):\n",
    "    '''\n",
    "    coefs is a list that contains a and b: [coef, intercept]\n",
    "    X is the features set\n",
    "\n",
    "    Returns class of X\n",
    "    '''\n",
    "    prob =sigmoid(coefs[0]*X + coefs[1])\n",
    "    cls =  np.where(prob>= 0.5,1,0)\n",
    "\n",
    "    return cls\n",
    "\n",
    "x_class = lreg.predict(X)\n",
    "x_class1 = predict_class(coefs,X)\n",
    "x_class[:5],x_class1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. On the plot add the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3,4)\n",
    "sigmoid =lambda x: 1/(1+np.exp(-x))\n",
    "y_prob = sigmoid(x*lreg.coef_[0][0]+lreg.intercept_[0])\n",
    "plt.title(\"X (1 dimension) and y\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "\n",
    "plt.scatter(X,y)\n",
    "plt.plot(x,y_prob,color=\"orange\")\n",
    "plt.scatter(X,x_class.clip(0.1,0.9),color=\"orange\")\n",
    "\n",
    "plt.plot([-3,4],[0.5,0.5],color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us repeat this process on 2-dimensional data. The goal is to focus on the decision boundary and to understand how the Logistic Regression create a line that separates the data. The code to plot the decision boundary is provided, however it is important to understand the way it works.\n",
    "\n",
    "*  Generate 500 data points using:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_features=2,\n",
    "                           n_redundant=0,\n",
    "                           n_samples=250,\n",
    "                           n_classes=2,\n",
    "                           n_clusters_per_class=1,\n",
    "                           flip_y=0.05,\n",
    "                           class_sep=3,\n",
    "                           random_state=43)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Fit the Logistic Regression on X and y and use the code below to plot the fitted sigmoid on the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg.fit(X,y)\n",
    "\n",
    "xx, yy = np.mgrid[-5:5:.01, -5:5:.01]\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "#if needed change the line below\n",
    "probs = lreg.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\",\n",
    "                      vmin=0, vmax=1)\n",
    "ax_c = f.colorbar(contour)\n",
    "ax_c.set_label(\"$P(y = 1)$\")\n",
    "ax_c.set_ticks([0, .25, .5, .75, 1])\n",
    "\n",
    "ax.scatter(X[:,0], X[:, 1], c=y, s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "ax.set(aspect=\"equal\",\n",
    "       xlim=(-5, 5), ylim=(-5, 5),\n",
    "       xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = np.arange(1,21).reshape(10,-1)\n",
    "y = np.zeros(10)\n",
    "y[7:] = 1\n",
    "\n",
    "X_train, X_test, y_train,  y_test = train_test_split(X,y,shuffle=False,test_size=0.2)\n",
    "\n",
    "print(f\"\"\"\n",
    "xtrain: {X_train}\n",
    "\n",
    "ytrain: {y_train}\n",
    "\n",
    "x_test: {X_test}\n",
    "\n",
    "y_test: {y_test}\n",
    "      \n",
    "\"\"\")\n",
    "train_prop = np.mean(y_train==1)\n",
    "test_prop = np.mean(y_test==1)\n",
    "\n",
    "train_prop,test_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(1,201).reshape(100,-1)\n",
    "y = np.zeros(100)\n",
    "y[70:] = 1\n",
    "\n",
    "X_train, X_test, y_train,  y_test = train_test_split(X,y,stratify=y,test_size=0.2)\n",
    "\n",
    "train_prop = np.mean(y_train==1)\n",
    "test_prop = np.mean(y_test==1)\n",
    "\n",
    "train_prop,test_prop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Breast Cancer prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this exercise is to use Logistic Regression to predict breast cancer. It is always important to understand the data before training any Machine Learning algorithm. The data is described in breast-cancer-wisconsin.names. I suggest to add manually the column names in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "\n",
    "cols = [\"SCN\"\n",
    ",\"CT\"\n",
    ",\"UCSI\"\n",
    ",\"UCSH\"\n",
    ",\"MA\"\n",
    ",\"SECS\"\n",
    ",\"BN\"\n",
    ",\"BC\"\n",
    ",\"NN\"\n",
    ",\"Mitoses\"\n",
    ",\"Class\"]\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/01-edu/public/refs/heads/master/subjects/ai/classification/data/breast-cancer-wisconsin.data\",names=cols,index_col=[\"SCN\"])\n",
    "data = data.apply(pd.to_numeric,errors=\"coerce\")\n",
    "data.fillna(data.median(),inplace=True)\n",
    "data.isnull().sum()\n",
    "\n",
    "X = data.drop(\"Class\",axis=1)\n",
    "y = data[\"Class\"]\n",
    "\n",
    "X_train, X_test, y_train,  y_test = train_test_split(X,y,stratify=y,test_size=0.2,random_state=43)\n",
    "\n",
    "train_prop = np.mean(y_train==2)\n",
    "test_prop = np.mean(y_test==2)\n",
    "\n",
    "train_prop,test_prop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression()\n",
    "lreg.fit(X_train,y_train)\n",
    "\n",
    "train_pred = lreg.predict(X_train)\n",
    "train_prob = lreg.predict_proba(X_train)\n",
    "test_pred = lreg.predict(X_test)\n",
    "test_prob = lreg.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "train pred :\n",
    "{train_pred[:5]}\n",
    "\n",
    "train probabilities :\n",
    "{train_prob[:5,1]}\n",
    "\n",
    "test pred :\n",
    "{test_pred[:5]}\n",
    "\n",
    "test prprobabilitiesed :\n",
    "{test_prob[:5,1]}\n",
    "\n",
    "train score: {lreg.score(X_train,y_train)}\n",
    "\n",
    "test score: {lreg.score(X_test,y_test)\n",
    "}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "test_cm = confusion_matrix(y_test,test_pred)\n",
    "train_cm = confusion_matrix(y_train,train_pred)\n",
    "print(f\"\"\"\n",
    "train confusion_matrix: \n",
    "{train_cm}\n",
    "\n",
    "test confusion_matrix: \n",
    "{test_cm}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex00",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
